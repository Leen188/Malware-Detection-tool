from django.shortcuts import render
from django.http import HttpResponse
from django.shortcuts import render
from .URLFeatures import URLFeatures
from .FilesFeatures import PDFAnalyzer
from django.http import HttpResponseRedirect, HttpResponse
import json
import concurrent.futures
import logging
import joblib
import os 
import numpy as np
import pandas as pd

def index(request):
    return render(request,'index.html')


def analyze_url(request):
    result = None
    result_json = None  # Define result_json here

    if request.method == 'POST':
        # logging setup code
        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        handler = logging.FileHandler('example.log')
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)

        # Check if a URL was submitted
        if 'url' in request.POST and request.POST['url']:
            url = request.POST['url']
            logger.debug(f'URL entered: {url}')

            # Your URL analysis code
            url_features = URLFeatures(url)
            methods = {  
                 'Dots': url_features.Dots,
                 'SubdomainLevel': url_features.SubdomainLevel,
                 'Path_level': url_features.Path_level,
                 'UrlLength': url_features.UrlLength,
                 'NumDash': url_features.NumDash,
                 'NumDashInHostname': url_features.NumDashInHostname,
                 'NumUnderscore': url_features.NumUnderscore,
                 'NumPercent': url_features.NumPercent,
                 'NumQueryComponents': url_features.NumQueryComponents,
                 'NumAmpersand': url_features.NumAmpersand,
                 'NumNumericChars': url_features.NumNumericChars,
                 'NoHttps': url_features.NoHttps,
                 'DomainInPaths': url_features.DomainInPaths,
                 'HostnameLength': url_features.HostnameLength,
                 'PathLength': url_features.PathLength,
                 'QueryLength': url_features.QueryLength,
                 'NumSensitiveWords': url_features.NumSensitiveWords,
                 'PctExtHyperlinks': url_features.PctExtHyperlinks,
                 'PctExtResourceUrls': url_features.PctExtResourceUrls,
                 'ExtFavicon': url_features.ExtFavicon,
                 'InsecureForms': url_features.InsecureForms,
                 'ExtFormAction': url_features.ExtFormAction,
                'PctNullSelfRedirectHyperlinks': url_features.PctNullSelfRedirectHyperlinks,
                 'FrequentDomainNameMismatch': url_features.FrequentDomainNameMismatch,
                  'SubmitInfoToEmail': url_features.SubmitInfoToEmail,
                  'IframeOrFrame': url_features.IframeOrFrame,
                  'MissingTitle': url_features.MissingTitle,
                  'AbnormalExtFormActionR': url_features.AbnormalExtFormActionR,
                  'AbnormalExtMetaScriptLinkRT': url_features.AbnormalExtMetaScriptLinkRT,
                  'PctExtNullSelfRedirectHyperlinksRT': url_features.PctExtNullSelfRedirectHyperlinksRT, 
              }
            with concurrent.futures.ThreadPoolExecutor() as executor:
                results = {name: executor.submit(method)
                           for name, method in methods.items()}
            results = {name: future.result()
                       for name, future in results.items()}
            for name, result in results.items():
                logger.debug(f'{name}: {result}')

            # Your prediction code
            xgb_model = joblib.load('base/ML/URL_ML/xgb_model.joblib')
            features = np.array(list(results.values())).reshape(1, -1)
            predictions = xgb_model.predict(features)
            
            # Convert numpy array to list
            result = predictions.tolist()

            
            # Check the prediction result
            if result[0] == 1:
                message = "The URL is safe"
            elif result[0] == 0:
                message = "The URL is not safe"


            # Convert predictions to JSON
            result_json = json.dumps(result)

            # Your DataFrame code
            df = pd.DataFrame([results])
            df.to_csv('results.csv', index=False)
   
    # Render hello.html with result and message
    return render(request, 'index.html', {'result': result_json, 'message': message})

def analyze_file(request):
    result = None
    result_json = None  # Define result_json here

    if request.method == 'POST':
        # logging setup code
        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        handler = logging.FileHandler('example2.log')
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)

        # Check if a file was uploaded
        if 'file' in request.FILES and request.FILES['file']:
            file = request.FILES['file']

            # Create an instance of PDFAnalyzer
            analyzer = PDFAnalyzer()

            # Analyze the PDF and get the predictions
            predictions = analyzer.analyze(file.name)
            
            # Convert numpy array to list
            result1 = predictions

            
    # Render hello.html with result
    return render(request, 'index.html', {'result1': result1})


def analyze_email(request):
    result = None
    result_json = None  # Define result_json here

    if request.method == 'POST':
        # logging setup code
        logger = logging.getLogger(__name__)
        logger.setLevel(logging.DEBUG)
        handler = logging.FileHandler('example3.log')
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)

        email = request.POST['email']
        logger.debug(f'entered Email: {email}')

        # Your prediction code
        rf_model = joblib.load('base/ML/Email_ML/rf_model.joblib')
        predictions = rf_model.predict([email])

        # Convert numpy array to list
        result2 = predictions.tolist()

        # Get the first element of the list
        result2 = result2[0]

        # Convert predictions to JSON
        # result_json = json.dumps(result2)

     # Render hello.html with result
    return render(request, 'index.html', {'result2': result2})
